Flashcard Journal

Day 1:

Set up the anki note model template as well as a script which will create a flashcard using the said template.
Took me a long time to find a good most frequently used 5000 words list (as I wanted them in order of frequency) but I eventually found one that aptly suited my needs, *(The Romance Languages and their Structures. First Series_ F.S. I1) Alphonse Juilland_ Vicenzo Traversa_ Antonio Beltramo_ Sebastiano di Blasi - Frequency dictionary of Italian words-De Gruyter Mouton*
Used https://www.ilovepdf.com/ to extract my desired pages from the original pdf.
converted the pdf into csv using https://convertio.co/pdf-csv/.

Day 2:

There are a few errors with the csv file. The extractor seemed to struggle with words containing accents, often replacing them with the letter Ã or symbols such as ¬. There are also more inconsistent errors. I began by removing all excess lines by removing all lines that do not start with numbers. I then removed all numbers. This left me with a few lines containing only whitespace which I tried to remove, but couldn't. After using print(repr(line)) i found out that i had the two following types of lines.

'   valente adj.         .   lucente adj.          cumulo n.           .;;;;;;\n'
';;;;;;\n'

It worked, however I noticed that I only had 5011 lines instead of 5014, this means that I must have lost 3 words in the process of cleaning. However since it is only an extremely minor % I will move on, I do not think it is worth the time or effort to try and find the missing 3 words as I don't even know where I could start and if it would even be possible.
I then removed all excess writing and whitespace from the rows, leaving me with only the words from the usage column.

Day 3:

I began with trying to remove the few excess symbols in the document of which I saw only three of: "© ¨ ¬". I wrote some code which allowed me to remove these symbols while keeping the accented symbols (e.g. Ã, é) that I needed. After running the code I found that all of the symbols were removed and somehow the Ã's were replaced with what looks to be the correct accented letters. This is strange and I'm not too sure why, perhaps its due to the python library understanding Ã to represent any accented letter and it then replaced it accurately taking the letters surrounding it in context (which was going to be my plan, utilising the original document as a reference point).
I tried for a while to compare the words in my file to the original file as well as a txt version of the file, to check if my words are correct. However, I could not complete this task due to the original file being so odd (which is perhaps why I had such a difficult time with the csv file). So I have manually checked and removed the one error I knew existed (J being at the end of a word). I may come back to this if I notice more errors in the future, however, for now this section seems to be complete.
I noticed some words being capitalised. I edited my code to make them into lower case however this did not work. I then printed into a txt file and it was completely fine. I then realised that the two capitalised words are singular words translating to "true" and "false", excel thinks that I want to write columns and is automatically capitalising them. Thus I left it in txt format as the txt format seems to work and is still readable through code.

Day 4:

Used code from api reference by chatgpt to make a basic text to speech generator. Tested all of the voices and they all sounded a bit odd and had foreign accents probably because they are optimised for english. So I decided on the google cloud api as an option due to the voices sounding good and the service being free.

Day 5:
Organised my project directory a little bit, watched videos on how to use google tts and ".gitignore". I have also decided on setting my api key as a permanent environmental variable on my computer as it is easier to use, it is my current only google project and it ensures that my api key is secure and not visible in git. I have also created a "Private" folder which contains my api key and any other sensitive information, it will be ignored so I can securely use my api key(s).